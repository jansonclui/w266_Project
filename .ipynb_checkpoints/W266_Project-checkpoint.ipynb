{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, sys, re, json, time, unittest\n",
    "import itertools, collections\n",
    "import re\n",
    "import operator\n",
    "from sklearn import datasets, linear_model\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in data to clean and separate into training and test set\n",
    "lines = []\n",
    "for line in open('listings_scores.csv').readlines():\n",
    "    data = line.split('\\t')\n",
    "    clean_desc = re.sub('[^A-Za-z]', ' ', data[0])\n",
    "    clean_score = re.sub(\"[^0-9]\", \"\", data[1])\n",
    "    lines.append([clean_desc,clean_score])\n",
    "    \n",
    "training_set = lines[:len(lines)/2]\n",
    "test_set = lines[len(lines)/2:]\n",
    "practice_set = lines[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for each in practice_set:\n",
    "    print each[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     /Users/janson/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n",
      "([u'plot', u':', u'two', u'teen', u'couples', u'go', u'to', u'a', u'church', u'party', u',', u'drink', u'and', u'then', u'drive', u'.', u'they', u'get', u'into', u'an', u'accident', u'.', u'one', u'of', u'the', u'guys', u'dies', u',', u'but', u'his', u'girlfriend', u'continues', u'to', u'see', u'him', u'in', u'her', u'life', u',', u'and', u'has', u'nightmares', u'.', u'what', u\"'\", u's', u'the', u'deal', u'?', u'watch', u'the', u'movie', u'and', u'\"', u'sorta', u'\"', u'find', u'out', u'.', u'.', u'.', u'critique', u':', u'a', u'mind', u'-', u'fuck', u'movie', u'for', u'the', u'teen', u'generation', u'that', u'touches', u'on', u'a', u'very', u'cool', u'idea', u',', u'but', u'presents', u'it', u'in', u'a', u'very', u'bad', u'package', u'.', u'which', u'is', u'what', u'makes', u'this', u'review', u'an', u'even', u'harder', u'one', u'to', u'write', u',', u'since', u'i', u'generally', u'applaud', u'films', u'which', u'attempt', u'to', u'break', u'the', u'mold', u',', u'mess', u'with', u'your', u'head', u'and', u'such', u'(', u'lost', u'highway', u'&', u'memento', u')', u',', u'but', u'there', u'are', u'good', u'and', u'bad', u'ways', u'of', u'making', u'all', u'types', u'of', u'films', u',', u'and', u'these', u'folks', u'just', u'didn', u\"'\", u't', u'snag', u'this', u'one', u'correctly', u'.', u'they', u'seem', u'to', u'have', u'taken', u'this', u'pretty', u'neat', u'concept', u',', u'but', u'executed', u'it', u'terribly', u'.', u'so', u'what', u'are', u'the', u'problems', u'with', u'the', u'movie', u'?', u'well', u',', u'its', u'main', u'problem', u'is', u'that', u'it', u\"'\", u's', u'simply', u'too', u'jumbled', u'.', u'it', u'starts', u'off', u'\"', u'normal', u'\"', u'but', u'then', u'downshifts', u'into', u'this', u'\"', u'fantasy', u'\"', u'world', u'in', u'which', u'you', u',', u'as', u'an', u'audience', u'member', u',', u'have', u'no', u'idea', u'what', u\"'\", u's', u'going', u'on', u'.', u'there', u'are', u'dreams', u',', u'there', u'are', u'characters', u'coming', u'back', u'from', u'the', u'dead', u',', u'there', u'are', u'others', u'who', u'look', u'like', u'the', u'dead', u',', u'there', u'are', u'strange', u'apparitions', u',', u'there', u'are', u'disappearances', u',', u'there', u'are', u'a', u'looooot', u'of', u'chase', u'scenes', u',', u'there', u'are', u'tons', u'of', u'weird', u'things', u'that', u'happen', u',', u'and', u'most', u'of', u'it', u'is', u'simply', u'not', u'explained', u'.', u'now', u'i', u'personally', u'don', u\"'\", u't', u'mind', u'trying', u'to', u'unravel', u'a', u'film', u'every', u'now', u'and', u'then', u',', u'but', u'when', u'all', u'it', u'does', u'is', u'give', u'me', u'the', u'same', u'clue', u'over', u'and', u'over', u'again', u',', u'i', u'get', u'kind', u'of', u'fed', u'up', u'after', u'a', u'while', u',', u'which', u'is', u'this', u'film', u\"'\", u's', u'biggest', u'problem', u'.', u'it', u\"'\", u's', u'obviously', u'got', u'this', u'big', u'secret', u'to', u'hide', u',', u'but', u'it', u'seems', u'to', u'want', u'to', u'hide', u'it', u'completely', u'until', u'its', u'final', u'five', u'minutes', u'.', u'and', u'do', u'they', u'make', u'things', u'entertaining', u',', u'thrilling', u'or', u'even', u'engaging', u',', u'in', u'the', u'meantime', u'?', u'not', u'really', u'.', u'the', u'sad', u'part', u'is', u'that', u'the', u'arrow', u'and', u'i', u'both', u'dig', u'on', u'flicks', u'like', u'this', u',', u'so', u'we', u'actually', u'figured', u'most', u'of', u'it', u'out', u'by', u'the', u'half', u'-', u'way', u'point', u',', u'so', u'all', u'of', u'the', u'strangeness', u'after', u'that', u'did', u'start', u'to', u'make', u'a', u'little', u'bit', u'of', u'sense', u',', u'but', u'it', u'still', u'didn', u\"'\", u't', u'the', u'make', u'the', u'film', u'all', u'that', u'more', u'entertaining', u'.', u'i', u'guess', u'the', u'bottom', u'line', u'with', u'movies', u'like', u'this', u'is', u'that', u'you', u'should', u'always', u'make', u'sure', u'that', u'the', u'audience', u'is', u'\"', u'into', u'it', u'\"', u'even', u'before', u'they', u'are', u'given', u'the', u'secret', u'password', u'to', u'enter', u'your', u'world', u'of', u'understanding', u'.', u'i', u'mean', u',', u'showing', u'melissa', u'sagemiller', u'running', u'away', u'from', u'visions', u'for', u'about', u'20', u'minutes', u'throughout', u'the', u'movie', u'is', u'just', u'plain', u'lazy', u'!', u'!', u'okay', u',', u'we', u'get', u'it', u'.', u'.', u'.', u'there', u'are', u'people', u'chasing', u'her', u'and', u'we', u'don', u\"'\", u't', u'know', u'who', u'they', u'are', u'.', u'do', u'we', u'really', u'need', u'to', u'see', u'it', u'over', u'and', u'over', u'again', u'?', u'how', u'about', u'giving', u'us', u'different', u'scenes', u'offering', u'further', u'insight', u'into', u'all', u'of', u'the', u'strangeness', u'going', u'down', u'in', u'the', u'movie', u'?', u'apparently', u',', u'the', u'studio', u'took', u'this', u'film', u'away', u'from', u'its', u'director', u'and', u'chopped', u'it', u'up', u'themselves', u',', u'and', u'it', u'shows', u'.', u'there', u'might', u\"'\", u've', u'been', u'a', u'pretty', u'decent', u'teen', u'mind', u'-', u'fuck', u'movie', u'in', u'here', u'somewhere', u',', u'but', u'i', u'guess', u'\"', u'the', u'suits', u'\"', u'decided', u'that', u'turning', u'it', u'into', u'a', u'music', u'video', u'with', u'little', u'edge', u',', u'would', u'make', u'more', u'sense', u'.', u'the', u'actors', u'are', u'pretty', u'good', u'for', u'the', u'most', u'part', u',', u'although', u'wes', u'bentley', u'just', u'seemed', u'to', u'be', u'playing', u'the', u'exact', u'same', u'character', u'that', u'he', u'did', u'in', u'american', u'beauty', u',', u'only', u'in', u'a', u'new', u'neighborhood', u'.', u'but', u'my', u'biggest', u'kudos', u'go', u'out', u'to', u'sagemiller', u',', u'who', u'holds', u'her', u'own', u'throughout', u'the', u'entire', u'film', u',', u'and', u'actually', u'has', u'you', u'feeling', u'her', u'character', u\"'\", u's', u'unraveling', u'.', u'overall', u',', u'the', u'film', u'doesn', u\"'\", u't', u'stick', u'because', u'it', u'doesn', u\"'\", u't', u'entertain', u',', u'it', u\"'\", u's', u'confusing', u',', u'it', u'rarely', u'excites', u'and', u'it', u'feels', u'pretty', u'redundant', u'for', u'most', u'of', u'its', u'runtime', u',', u'despite', u'a', u'pretty', u'cool', u'ending', u'and', u'explanation', u'to', u'all', u'of', u'the', u'craziness', u'that', u'came', u'before', u'it', u'.', u'oh', u',', u'and', u'by', u'the', u'way', u',', u'this', u'is', u'not', u'a', u'horror', u'or', u'teen', u'slasher', u'flick', u'.', u'.', u'.', u'it', u\"'\", u's', u'just', u'packaged', u'to', u'look', u'that', u'way', u'because', u'someone', u'is', u'apparently', u'assuming', u'that', u'the', u'genre', u'is', u'still', u'hot', u'with', u'the', u'kids', u'.', u'it', u'also', u'wrapped', u'production', u'two', u'years', u'ago', u'and', u'has', u'been', u'sitting', u'on', u'the', u'shelves', u'ever', u'since', u'.', u'whatever', u'.', u'.', u'.', u'skip', u'it', u'!', u'where', u\"'\", u's', u'joblo', u'coming', u'from', u'?', u'a', u'nightmare', u'of', u'elm', u'street', u'3', u'(', u'7', u'/', u'10', u')', u'-', u'blair', u'witch', u'2', u'(', u'7', u'/', u'10', u')', u'-', u'the', u'crow', u'(', u'9', u'/', u'10', u')', u'-', u'the', u'crow', u':', u'salvation', u'(', u'4', u'/', u'10', u')', u'-', u'lost', u'highway', u'(', u'10', u'/', u'10', u')', u'-', u'memento', u'(', u'10', u'/', u'10', u')', u'-', u'the', u'others', u'(', u'9', u'/', u'10', u')', u'-', u'stir', u'of', u'echoes', u'(', u'8', u'/', u'10', u')'], u'neg')\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "#nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "from nltk.corpus import movie_reviews\n",
    "nltk.download('movie_reviews')\n",
    "document = [(list(movie_reviews.words(fileid)), category) for category in movie_reviews.categories() for fileid in movie_reviews.fileids(category)]\n",
    "print document[0]\n",
    "#nltk.download('tagsets')\n",
    "#nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from nltk.corpus import stopwords\n",
    "#removes stopwords\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "def cleaner(data_set):\n",
    "    corpus = defaultdict(list)\n",
    "    for text,score in data_set:\n",
    "        for word in nltk.pos_tag(text.split()):\n",
    "            if word[0].lower() not in stop_words and score != '':\n",
    "                if int(score) < 101 and int(score) > -1:\n",
    "                    corpus[word[0].lower(), word[1]].append(int(score))\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "282\n"
     ]
    }
   ],
   "source": [
    "practice_corpus = cleaner(practice_set)\n",
    "\n",
    "print len(practice_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_corpus = defaultdict(list)\n",
    "training_corpus = cleaner(training_set)\n",
    "\n",
    "#sorts corpus\n",
    "keys = sorted(training_corpus.keys())\n",
    "for key in keys:\n",
    "    trained_corpus[key] = sum(training_corpus[key])/len(training_corpus[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "100\n",
      "66091\n"
     ]
    }
   ],
   "source": [
    "print min(training_corpus['and', 'CC'])\n",
    "print max(training_corpus['and', 'CC'])\n",
    "print len(training_corpus['and', 'CC'])\n",
    "#print training_corpus['and', 'CC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Score: 94 - Actual Score: 95 - Accuracy: 0.989473684211\n",
      "Predicted Score: 94 - Actual Score: 92 - Accuracy: 1.02173913043\n",
      "Predicted Score: 94 - Actual Score: 98 - Accuracy: 0.959183673469\n",
      "Predicted Score: 94 - Actual Score: 97 - Accuracy: 0.969072164948\n",
      "Predicted Score: 95 - Actual Score: 100 - Accuracy: 0.95\n",
      "Predicted Score: 94 - Actual Score: 92 - Accuracy: 1.02173913043\n",
      "Predicted Score: 94 - Actual Score: 96 - Accuracy: 0.979166666667\n",
      "Predicted Score: 94 - Actual Score: 96 - Accuracy: 0.979166666667\n",
      "Predicted Score: 95 - Actual Score: 100 - Accuracy: 0.95\n",
      "Predicted Score: 94 - Actual Score: 88 - Accuracy: 1.06818181818\n",
      "Predicted Score: 94 - Actual Score: 99 - Accuracy: 0.949494949495\n",
      "Predicted Score: 95 - Actual Score: 100 - Accuracy: 0.95\n",
      "Predicted Score: 94 - Actual Score: 80 - Accuracy: 1.175\n",
      "Predicted Score: 94 - Actual Score: 99 - Accuracy: 0.949494949495\n",
      "Predicted Score: 94 - Actual Score: 93 - Accuracy: 1.01075268817\n",
      "Predicted Score: 94 - Actual Score: 99 - Accuracy: 0.949494949495\n",
      "Predicted Score: 94 - Actual Score: 97 - Accuracy: 0.969072164948\n",
      "Predicted Score: 94 - Actual Score: 93 - Accuracy: 1.01075268817\n",
      "Predicted Score: 94 - Actual Score: 95 - Accuracy: 0.989473684211\n",
      "Predicted Score: 94 - Actual Score: 100 - Accuracy: 0.94\n",
      "Predicted Score: 94 - Actual Score: 99 - Accuracy: 0.949494949495\n",
      "Predicted Score: 94 - Actual Score: 98 - Accuracy: 0.959183673469\n",
      "Predicted Score: 94 - Actual Score: 100 - Accuracy: 0.94\n",
      "Predicted Score: 94 - Actual Score: 96 - Accuracy: 0.979166666667\n",
      "Predicted Score: 94 - Actual Score: 97 - Accuracy: 0.969072164948\n",
      "Predicted Score: 94 - Actual Score: 99 - Accuracy: 0.949494949495\n",
      "Predicted Score: 94 - Actual Score: 98 - Accuracy: 0.959183673469\n",
      "Predicted Score: 94 - Actual Score: 99 - Accuracy: 0.949494949495\n",
      "Predicted Score: 94 - Actual Score: 100 - Accuracy: 0.94\n",
      "Predicted Score: 94 - Actual Score: 90 - Accuracy: 1.04444444444\n",
      "Predicted Score: 94 - Actual Score: 93 - Accuracy: 1.01075268817\n",
      "Predicted Score: 94 - Actual Score: 95 - Accuracy: 0.989473684211\n",
      "Predicted Score: 94 - Actual Score: 94 - Accuracy: 1.0\n",
      "Predicted Score: 94 - Actual Score: 92 - Accuracy: 1.02173913043\n",
      "Predicted Score: 94 - Actual Score: 100 - Accuracy: 0.94\n",
      "Predicted Score: 94 - Actual Score: 98 - Accuracy: 0.959183673469\n",
      "Predicted Score: 94 - Actual Score: 95 - Accuracy: 0.989473684211\n",
      "Predicted Score: 94 - Actual Score: 95 - Accuracy: 0.989473684211\n",
      "Predicted Score: 94 - Actual Score: 99 - Accuracy: 0.949494949495\n",
      "Predicted Score: 93 - Actual Score: 40 - Accuracy: 2.325\n",
      "Predicted Score: 94 - Actual Score: 100 - Accuracy: 0.94\n",
      "Predicted Score: 94 - Actual Score: 92 - Accuracy: 1.02173913043\n",
      "Predicted Score: 94 - Actual Score: 99 - Accuracy: 0.949494949495\n",
      "Predicted Score: 95 - Actual Score: 100 - Accuracy: 0.95\n",
      "Predicted Score: 94 - Actual Score: 97 - Accuracy: 0.969072164948\n",
      "Predicted Score: 94 - Actual Score: 98 - Accuracy: 0.959183673469\n",
      "Predicted Score: 95 - Actual Score: 100 - Accuracy: 0.95\n",
      "Predicted Score: 94 - Actual Score: 100 - Accuracy: 0.94\n",
      "Predicted Score: 94 - Actual Score: 100 - Accuracy: 0.94\n",
      "Predicted Score: 94 - Actual Score: 96 - Accuracy: 0.979166666667\n"
     ]
    }
   ],
   "source": [
    "practice_set = lines[:50]\n",
    "practice_corpus = defaultdict(list)\n",
    "trained_keys = trained_corpus.keys()\n",
    "\n",
    "for text,score in practice_set:\n",
    "    tot_score = 0\n",
    "    count = 0\n",
    "    for word in nltk.pos_tag(text.split()):\n",
    "        if word in trained_keys:\n",
    "            #print word, trained_corpus[word]\n",
    "            tot_score += trained_corpus[word]\n",
    "            count += 1\n",
    "    print \"Predicted Score: \" + str(tot_score/count) + \" - Actual Score: \" + str(score) + \" - Accuracy: \" + str(float(tot_score/count)/float(score))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.054347826087\n"
     ]
    }
   ],
   "source": [
    "print float(5)/92"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.help.upenn_tagset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separates each review into a dictionary of words and score\n",
    "temp_dict = []\n",
    "dictionary = {}\n",
    "bow = []\n",
    "for each in practice_set:\n",
    "    sentence = each[0].split(\" \")\n",
    "    bow.append(each[0])\n",
    "    for word in sentence:\n",
    "        if word != '':\n",
    "            temp_dict.append([word.lower(),each[1]])\n",
    "\n",
    "temp_dict = sorted(temp_dict)\n",
    "\n",
    "for each in temp_dict:\n",
    "    if each[0] in dictionary:\n",
    "        dictionary[each[0]].append(int(each[1]))\n",
    "    else:\n",
    "        dictionary[each[0]] = [int(each[1])]\n",
    "    \n",
    "\n",
    "keys = dictionary.keys()\n",
    "total = 0\n",
    "for each in keys:\n",
    "    total = sum(dictionary[each])/len(dictionary[each])\n",
    "    \n",
    "    dictionary[each] = total\n",
    "    total = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bag of words\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "bag_of_words = vectorizer.fit(bow)\n",
    "bag_of_words = vectorizer.transform(bow)\n",
    "print bag_of_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#word_score = [(k, v) for k, v in dictionary.items()] \n",
    "regr = linear_model.LinearRegression()\n",
    "words_train = dictionary.keys()\n",
    "score_train = dictionary.values()\n",
    "\n",
    "words_train = np.array(words_train)\n",
    "score_train = np.array(score_train)\n",
    "\n",
    "#words_train = words_train.reshape(-1,1)\n",
    "#score_train = score_train.reshape(-1,1)\n",
    "#print words_train.shape\n",
    "#print score_train.shape\n",
    "\n",
    "#regr.fit(words_train, score_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt; plt.rcdefaults()\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "\n",
    "y_pos = np.arange(len(words_train))\n",
    "performance = score_train\n",
    " \n",
    "plt.bar(y_pos, performance, align='center')\n",
    "plt.xticks(y_pos, words_train)\n",
    "plt.ylabel('Usage')\n",
    "plt.title('Programming language usage')\n",
    " \n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
